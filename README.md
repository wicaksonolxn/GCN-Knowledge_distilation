# GCN-Knowledge_distilation
This is a repository on how to utilize 2 types of Knowledge distilation on a regression poblem, Feature based Knowledge distilation and Response based knowledge distilation. 
I use these paper as a reference : https://arxiv.org/pdf/1908.00858.pdf , https://arxiv.org/pdf/1412.6550.pdf

###bellow are the best tuned parameter alpha, Alpha is the ratio of used theacher output and ground truth output as a method of Knowledge distilation 
![Best Condition](https://github.com/Wicaksonolxn/GCN-Knowledge_distilation/assets/134767413/98a66560-1d60-4380-93d8-ed6a0710e2ef)

### bellow are the result of Knowledge distilation On between control groups, Student model (Reduced paremeters)
, Teacher model(Base model) and Distilled Model(Reduced Parameters with Knowledge Distilation Assistance)
![Best Condition2](https://github.com/Wicaksonolxn/GCN-Knowledge_distilation/assets/134767413/bf8217fc-aa1a-4521-9e08-a4e241c6f413)

